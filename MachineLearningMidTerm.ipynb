{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MachineLearningMidTerm.ipynb",
      "provenance": [],
      "mount_file_id": "1QbexKAbQNc6LN8m_ixQhBqls4Oh3NGC5",
      "authorship_tag": "ABX9TyNyhcw3eTM95PCGxjirkILG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenduyhieu201/machineLearning/blob/main/MachineLearningMidTerm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NwiMvYi1Sc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564e46a8-8a5d-4be7-cf5c-4fb15660f3f7"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        " \n",
        "input_path = \"../content/DATA_CHAMBER_2021/\"\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"Using CUDA\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIQiBjNfdmvW",
        "outputId": "8912633d-2482-42e4-8308-bd0ec79ad163"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PSw2Kb5Wz2B"
      },
      "source": [
        "# Mục mới"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5UX1sxih2PR"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/DATA_CHAMBER_2021.zip\" -d \"./\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFR8GvNkaAF5"
      },
      "source": [
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FW4RZ0ziu_T"
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.CenterCrop(64),\n",
        "#         transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "#         transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'validation':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.CenterCrop(64),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'train': \n",
        "    ImageFolderWithPaths(input_path + 'train', data_transforms['train']),\n",
        "    'validation': \n",
        "    ImageFolderWithPaths(input_path + 'test', data_transforms['validation'])\n",
        "}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','validation']}\n",
        "\n",
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(image_datasets['train'],\n",
        "                                batch_size=8,\n",
        "                                shuffle=True,\n",
        "                                num_workers=2),  # for Kaggle\n",
        "    'validation':\n",
        "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
        "                                batch_size=8,\n",
        "                                shuffle=True,\n",
        "                                num_workers=2)  # for Kaggle\n",
        "}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyfW1_t9lmS7",
        "outputId": "298235bb-f59c-4d66-a3a1-81c12c209bd4"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZKEud03lpoc",
        "outputId": "c171c376-e230-4931-de11-d13cccee393d"
      },
      "source": [
        "!pip install efficientnet_pytorch "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=9668f0e9c3fbb7e9124817732e5bacb5bf98e7f926ef71e4d905c9eca3d664c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-HzUGylmKl8"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnp9gIXfl5FA"
      },
      "source": [
        "model = models.resnet50(pretrained = True).cuda()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False   \n",
        "    \n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 3)).to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qngLYITdXzge"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(),lr=0.001,momentum=0.9)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1E9cWxzX3H0"
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=3):\n",
        "    train_batches = len(dataloaders['train'])\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for i,data in enumerate(dataloaders[phase]):\n",
        "                inputs, labels,_ = data\n",
        "                print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(image_datasets[phase])\n",
        "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
        "                                                        epoch_loss,\n",
        "                                                        epoch_acc))\n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GieXz6fYX-kj",
        "outputId": "82d1c222-8152-4c62-a0fa-504d5a4afcab"
      },
      "source": [
        "model_trained = train_model(model, criterion, optimizer, num_epochs=20)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.7770, acc: 0.6551\n",
            "Epoch 2/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.5888, acc: 0.7561\n",
            "Epoch 3/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.5137, acc: 0.7931\n",
            "Epoch 4/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.4325, acc: 0.8315\n",
            "Epoch 5/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.3705, acc: 0.8605\n",
            "Epoch 6/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.3392, acc: 0.8700\n",
            "Epoch 7/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.3017, acc: 0.8869\n",
            "Epoch 8/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2777, acc: 0.8962\n",
            "Epoch 9/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2380, acc: 0.9120\n",
            "Epoch 10/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2238, acc: 0.9128\n",
            "Epoch 11/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2102, acc: 0.9199\n",
            "Epoch 12/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2108, acc: 0.9214\n",
            "Epoch 13/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2024, acc: 0.9238\n",
            "Epoch 14/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1943, acc: 0.9250\n",
            "Epoch 15/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1836, acc: 0.9326\n",
            "Epoch 16/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1701, acc: 0.9382\n",
            "Epoch 17/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1702, acc: 0.9375\n",
            "Epoch 18/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1650, acc: 0.9394\n",
            "Epoch 19/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1526, acc: 0.9436\n",
            "Epoch 20/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1484, acc: 0.9449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owrzt5RAX_tA"
      },
      "source": [
        "def test_model(model, criterion, optimizer):\n",
        "    labels_input=list()\n",
        "    labels_output=list()\n",
        "    vid_id = list()\n",
        "    for phase in ['validation']:\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels, fname in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            labels_input= labels_input + labels.tolist()\n",
        "            for f in fname:\n",
        "                vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            labels_output= labels_output + preds.tolist()\n",
        "    return labels_input,labels_output,vid_id\n",
        "            \n",
        "y_true,y_pred,vid_id = test_model(model, criterion, optimizer)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhcYt7pyYIb8",
        "outputId": "fded0985-1a31-4567-cdb7-e553eb90c84a"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "print(classification_report(y_true,y_pred))\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.68      0.68       409\n",
            "           1       0.44      0.83      0.58       367\n",
            "           2       0.78      0.49      0.60       831\n",
            "\n",
            "    accuracy                           0.61      1607\n",
            "   macro avg       0.64      0.66      0.62      1607\n",
            "weighted avg       0.68      0.61      0.61      1607\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.612321095208463"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBzldMAXYMKc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(list(zip(y_true,y_pred,vid_id)),\n",
        "               columns =['y_true','y_pred','vid_id'])\n",
        "df.to_csv('df.csv',encoding='utf-8',index=False)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxk87kxNYPni",
        "outputId": "89d134b9-eb31-4650-ba77-eb4f212002ec"
      },
      "source": [
        "vid_list = list(set(df['vid_id'].values))\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for vid in vid_list:\n",
        "    #print(vid)\n",
        "    tmp_df = df[df['vid_id']==vid]\n",
        "    #print(len(tmp_df))\n",
        "    vid_pred = tmp_df['y_pred'].mode().values[0]\n",
        "    vid_label = tmp_df['y_true'].mode().values[0]\n",
        "    y_true.append(vid_label)\n",
        "    y_pred.append(vid_pred)\n",
        "    #print(vid_label,\"\\n\",vid_pred)\n",
        "    \n",
        "    print('vid: {} label: {} pred: {}'.format(vid,vid_label,vid_pred))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vid: 181 label: 0 pred: 0\n",
            "vid: 177 label: 0 pred: 0\n",
            "vid: 180 label: 2 pred: 2\n",
            "vid: 174 label: 1 pred: 1\n",
            "vid: 192 label: 0 pred: 0\n",
            "vid: 173 label: 2 pred: 2\n",
            "vid: 187 label: 2 pred: 2\n",
            "vid: 178 label: 0 pred: 0\n",
            "vid: 183 label: 0 pred: 2\n",
            "vid: 161 label: 1 pred: 1\n",
            "vid: 189 label: 1 pred: 1\n",
            "vid: 163 label: 2 pred: 2\n",
            "vid: 195 label: 2 pred: 2\n",
            "vid: 194 label: 1 pred: 1\n",
            "vid: 159 label: 1 pred: 1\n",
            "vid: 184 label: 2 pred: 2\n",
            "vid: 165 label: 0 pred: 0\n",
            "vid: 168 label: 0 pred: 0\n",
            "vid: 158 label: 0 pred: 0\n",
            "vid: 176 label: 0 pred: 0\n",
            "vid: 188 label: 2 pred: 2\n",
            "vid: 182 label: 2 pred: 2\n",
            "vid: 193 label: 2 pred: 1\n",
            "vid: 179 label: 1 pred: 1\n",
            "vid: 175 label: 1 pred: 1\n",
            "vid: 191 label: 0 pred: 0\n",
            "vid: 172 label: 2 pred: 2\n",
            "vid: 160 label: 2 pred: 1\n",
            "vid: 157 label: 1 pred: 1\n",
            "vid: 186 label: 1 pred: 1\n",
            "vid: 167 label: 2 pred: 0\n",
            "vid: 190 label: 1 pred: 1\n",
            "vid: 164 label: 2 pred: 2\n",
            "vid: 171 label: 0 pred: 2\n",
            "vid: 166 label: 1 pred: 1\n",
            "vid: 185 label: 1 pred: 1\n",
            "vid: 170 label: 2 pred: 1\n",
            "vid: 162 label: 1 pred: 1\n",
            "vid: 169 label: 0 pred: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmIGKbgmYSyz",
        "outputId": "a0370f68-910a-44ad-c1d6-56f69adf242f"
      },
      "source": [
        "accuracy_score(y_true,y_pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8461538461538461"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}